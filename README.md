# mcas-gmra
gmra algorithm with ibm mcas nvram technology


# Dependencies
1) tensorflow (doesn't matter cpu or gpu version...using it to load mnist)
2) pytorch
3) sklearn
4) tqdm (python package)
5) cmake (> 3.0)
6) mcas (and pymm)

## NOTE
-mcas installs to your system python interpreter. Therefore, the rest of these dependencies must be installed to the system interpreter as well (will still work if installed to the user (--user) system environment).

-Special note about pytorch. If you have a prebuilt binary, then you *must* have the cuda/cudnn/nccl versions that the prebuilt version is expecting. Normally this isn't a problem when using pytorch, however this will cause the libtorch cmake toolchain to error and the build to fail.

-I am currently testing whether building pytorch from source fixes this problem, so standby.

## UPDATE
if you are getting an error from the pytorch cmake toolchain about not being able to find cuda/cudnn/nccl, you need to either install the expected libraries (and add them to your LD_LIBRARY_PATH, etc.) OR you can compile pytorch from source. The cmake toolchain is autogenerated and will NOT have gpu dependencies for a cpu only build!


# Building
there are git submodules so be sure to run:

```git submodule update --init --recursive```

Then, cd to the pymm-gmra directory. The code can be build using
```python3 setup.py build```

and then installed using
```python3 setup.py install --user```

Running the install command will also build the code (if unbuilt or modified).

Finally, if you cd into the examples directory, you will see examples of running the code on mnist. I recommend trying

mnist_nopymm_cpp.py if you do *not* have pymm installed, otherwise mnist_pymm_cpp.py

The *_cpp.py scripts will use the c++ data structures instead of the pure python versions (which the other scripts will use). Warning: pure python scripts are very, very, slow.

# Code

The experiments folder contains code for experiments with GMRA embeddings on SNAP and Network Repository datasets for link prediction and other tasks

The LANL_analysis contains code for experiments with GMRA embeddings on the LANL dataset including anomaly detection and node classification

The source code to generate the GMRA embeddings is in the pymm-gmra/pysrc folder. There are also c implementations of the covertree and dyadic tree that can be built for optimization

pymm-gmra/pysrc/trees contains the code for the tree structures, and utils contains code for helper functions including inverse code and extracting embeddings code

The pymm-gmra/experiments folders show examples of how to run the code on various datasets. 

For inverse, see pymm-gmra/experiments/mnist/dram/gmra_inverse.py to generate the inverse and then display_inverse.py to display them as images

For embeddings, see pymm-gmra/experiments/[helix, graphs]/dram/gmra.py. Note that you will need to input a path to the covertree json file to run, which can be generated by running pymm-gmra/experiments/[helix, graphs]/build_covertree.py. You can compute the max scale for a new dataset with the max_scale file, but for the datasets included it should be hard coded to be correct.



